**SLIP 28_1**
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

# Load dataset
data = fetch_20newsgroups(subset='train')
test_data = fetch_20newsgroups(subset='test')

# Convert text to feature vectors
vectorizer = CountVectorizer(stop_words='english')
X_train = vectorizer.fit_transform(data.data)
X_test = vectorizer.transform(test_data.data)

# Train model
model = MultinomialNB()
model.fit(X_train, data.target)

# Predict
y_pred = model.predict(X_test)

# Accuracy
print("Accuracy:", round(accuracy_score(test_data.target, y_pred) * 100, 2), "%")

# Test on a custom news text
sample = ["Apple releases a new version of the iPhone with AI features."]
pred = model.predict(vectorizer.transform(sample))
print("\nPredicted Category:", data.target_names[pred[0]])


**SLIP 28_2**
from sklearn.datasets import load_iris
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score

# Load data
iris = load_iris()
X, y = iris.data, iris.target
names = iris.target_names

# Trainâ€“test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Try all kernels
kernels = ["linear", "poly", "rbf", "sigmoid"]
print("Kernel Accuracies:")
for k in kernels:
    m = SVC(kernel=k).fit(X_train, y_train)
    print(k, "=", round(accuracy_score(y_test, m.predict(X_test)), 4))

# Final model (best kernel = rbf)
model = SVC(kernel="rbf").fit(X_train, y_train)

# Confusion Matrix
print("\nConfusion Matrix:\n", confusion_matrix(y_test, model.predict(X_test)))

# User Input
print("\nEnter flower features:")
sl = float(input("Sepal Length: "))
sw = float(input("Sepal Width: "))
pl = float(input("Petal Length: "))
pw = float(input("Petal Width: "))

pred = model.predict([[sl, sw, pl, pw]])[0]
print("\nPredicted Flower Type:", names[pred])
